import pandas as pd
from sqlalchemy import create_engine, text
from sqlalchemy.exc import OperationalError
import json
from ast import literal_eval
import numpy as np
import psycopg2 
from io import StringIO
from pandas.io import sql as pd_sql 

# --- 1. ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡∏Å‡∏≤‡∏£‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• (‡πÉ‡∏ä‡πâ‡∏Ñ‡πà‡∏≤‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ô) ---
DB_USER = 'DB_AIE321_BIG_DATA'
DB_PASSWORD = '321bigdatawork'
DB_HOST = 'localhost' 
DB_PORT = '6666'      
DB_NAME = 'AIE321' 

# ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ Schema ‡πÅ‡∏•‡∏∞ Table
RAW_SCHEMA = 'raw_data'
RAW_TABLE = 'tmdb_movies_raw'
PRODUCTION_SCHEMA = 'production'
MOVIE_FACTS_TABLE = 'movie_facts'
GENRE_SUMMARY_TABLE = 'genre_average_revenue'

CONN_STRING = f"dbname={DB_NAME} user={DB_USER} password={DB_PASSWORD} host={DB_HOST} port={DB_PORT}"
FULL_FACTS_TABLE = f'"{PRODUCTION_SCHEMA}"."{MOVIE_FACTS_TABLE}"'
FULL_GENRE_TABLE = f'"{PRODUCTION_SCHEMA}"."{GENRE_SUMMARY_TABLE}"'

# --- 2. ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏ä‡πà‡∏ß‡∏¢‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£ JSON/Array (‡πÉ‡∏ä‡πâ parse_and_extract_names ‡πÄ‡∏î‡∏¥‡∏°) ---
def parse_and_extract_names(json_string):
    """‡πÅ‡∏õ‡∏•‡∏á String ‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡πá‡∏ô Comma-Separated Values (CSV) ‡πÉ‡∏´‡πâ‡πÄ‡∏õ‡πá‡∏ô List ‡∏Ç‡∏≠‡∏á‡∏ä‡∏∑‡πà‡∏≠"""
    if pd.isna(json_string) or not isinstance(json_string, str) or json_string.strip() == '':
        return []
    
    # ‡πÉ‡∏ä‡πâ logic ‡∏Å‡∏≤‡∏£‡πÅ‡∏¢‡∏Å String ‡∏î‡πâ‡∏ß‡∏¢‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏´‡∏°‡∏≤‡∏¢‡∏Ñ‡∏≠‡∏°‡∏°‡∏≤
    names = [name.strip() for name in json_string.split(',')]
    
    # ‡∏Å‡∏£‡∏≠‡∏á‡∏Ñ‡πà‡∏≤‡∏ß‡πà‡∏≤‡∏á‡∏ó‡∏µ‡πà‡∏≠‡∏≤‡∏à‡πÄ‡∏Å‡∏¥‡∏î‡∏à‡∏≤‡∏Å‡∏Å‡∏≤‡∏£‡πÅ‡∏¢‡∏Å
    return [name for name in names if name]

# --- 3. ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏ä‡πà‡∏ß‡∏¢‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡πÅ‡∏•‡∏∞ Bulk Copy ---
def create_table_and_bulk_copy(engine, conn_string, df, table_name_unquoted, table_name_quoted, schema_name):
    """‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡πÄ‡∏õ‡∏•‡πà‡∏≤‡πÅ‡∏•‡∏∞‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏î‡πâ‡∏ß‡∏¢ COPY EXPERT"""
    from pandas.io import sql as pd_sql 
    
    try:
        # A. ‡πÉ‡∏ä‡πâ Pandas ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á CREATE TABLE (DDL)
        table_ddl = pd_sql.get_schema(
            df.head(0),
            name=table_name_unquoted, 
            con=engine, 
            keys=None, 
            schema=schema_name
        )
        
        # B. ‡∏•‡∏ö‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡πÄ‡∏Å‡πà‡∏≤‡πÅ‡∏•‡∏∞‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡πÉ‡∏´‡∏°‡πà
        with engine.begin() as conn:
            conn.execute(text(f"DROP TABLE IF EXISTS {schema_name}.{table_name_unquoted} CASCADE"))
            conn.execute(text(table_ddl))
        
        # C. ‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏î‡πâ‡∏ß‡∏¢ Bulk Copy
        buffer = StringIO()
        df.to_csv(buffer, index=False, header=False, sep='\t', encoding='utf-8') 
        buffer.seek(0)
        
        copy_command = f"""COPY {table_name_quoted} FROM STDIN WITH (FORMAT CSV, DELIMITER E'\\t')"""
        
        with psycopg2.connect(conn_string) as conn:
            with conn.cursor() as cursor:
                cursor.copy_expert(copy_command, buffer) 
            conn.commit() 
        
        return True

    except Exception as e:
        print(f"[ERROR] Bulk Copy to {schema_name}.{table_name_unquoted} Failed: {e}")
        raise

# --- 4. ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏´‡∏•‡∏±‡∏Å‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÅ‡∏õ‡∏•‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• (The Refinery) ---
def transform_data():
    try:
        # 1. ‡∏™‡∏£‡πâ‡∏≤‡∏á Engine ‡πÅ‡∏•‡∏∞ Schema Production
        engine = create_engine(f'postgresql://{DB_USER}:{DB_PASSWORD}@{DB_HOST}:{DB_PORT}/{DB_NAME}')
        with engine.begin() as conn:
            conn.execute(text(f"CREATE SCHEMA IF NOT EXISTS {PRODUCTION_SCHEMA}"))
            print(f"[SUCCESS] Schema '{PRODUCTION_SCHEMA}' ‡∏ñ‡∏π‡∏Å‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏£‡πâ‡∏≠‡∏¢‡πÅ‡∏•‡πâ‡∏ß")
        
        # 2. ‡∏≠‡πà‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏î‡∏¥‡∏ö
        print(f"‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏≠‡πà‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏î‡∏¥‡∏ö‡∏à‡∏≤‡∏Å {RAW_SCHEMA}.{RAW_TABLE}...")
        with psycopg2.connect(CONN_STRING) as conn:
            query = f"SELECT * FROM {RAW_SCHEMA}.{RAW_TABLE}"
            df = pd.read_sql_query(query, con=conn) 
        print(f"[SUCCESS] ‡∏≠‡πà‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏¥‡πâ‡∏ô ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡πÅ‡∏ñ‡∏ß: {len(df):,}")
        
        # 3. Data Cleaning ‡πÅ‡∏•‡∏∞ Feature Engineering (‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Å‡∏≤‡∏£‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÅ‡∏õ‡∏•‡∏á)
        json_cols = ['genres', 'production_countries', 'production_companies', 'spoken_languages', 'cast', 'writers', 'producers']
        for col in json_cols:
            df[f'{col}_list'] = df[col].astype(str).apply(parse_and_extract_names)
            
        numeric_cols = ['revenue', 'budget', 'runtime', 'vote_count', 'imdb_votes', 'imdb_rating', 'popularity']
        for col in numeric_cols:
            df[col] = pd.to_numeric(df[col], errors='coerce')

        df['release_year'] = pd.to_datetime(df['release_date'], errors='coerce').dt.year
        df['movie_fact_id'] = df['id'].astype('Int64') 

        movie_facts_cols = [
            'movie_fact_id', 'title', 'original_title', 'release_year', 'release_date',
            'status', 'runtime', 'budget', 'revenue', 'vote_average', 'vote_count',
            'imdb_rating', 'imdb_votes', 'popularity', 'original_language',
            'genres_list', 'production_countries_list'
        ]
        df_facts = df[movie_facts_cols].copy()
        
        # üö® NEW FILTER: ‡∏Å‡∏£‡∏≠‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏´‡πâ‡πÄ‡∏´‡∏•‡∏∑‡∏≠‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡πÅ‡∏ñ‡∏ß‡∏ó‡∏µ‡πà‡∏°‡∏µ imdb_rating ‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô üö®
        rows_before_filter = len(df_facts)
        df_facts = df_facts[df_facts['imdb_rating'].notna()].copy()
        rows_after_filter = len(df_facts)
        
        print(f"--- ‡∏Å‡∏£‡∏≠‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏¥‡πâ‡∏ô (‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡πÅ‡∏ñ‡∏ß‡∏ó‡∏µ‡πà‡∏°‡∏µ IMDb Rating) ---")
        print(f"‡πÅ‡∏ñ‡∏ß‡∏ñ‡∏π‡∏Å‡∏•‡∏î‡∏à‡∏≤‡∏Å {rows_before_filter:,} ‡πÄ‡∏´‡∏•‡∏∑‡∏≠ {rows_after_filter:,}")
        
        
        # 4. ‡πÇ‡∏´‡∏•‡∏î‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡∏´‡∏•‡∏±‡∏Å: production.movie_facts (‡πÉ‡∏ä‡πâ df_facts ‡∏ó‡∏µ‡πà‡∏ñ‡∏π‡∏Å‡∏Å‡∏£‡∏≠‡∏á‡πÅ‡∏•‡πâ‡∏ß)
        print(f"‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÇ‡∏´‡∏•‡∏î‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡∏´‡∏•‡∏±‡∏Å {PRODUCTION_SCHEMA}.{MOVIE_FACTS_TABLE} ‡∏î‡πâ‡∏ß‡∏¢ Bulk Copy...")
        
        df_facts_copy = df_facts.copy()
        # ‡πÅ‡∏õ‡∏•‡∏á‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå List ‡πÄ‡∏õ‡πá‡∏ô String ‡∏Å‡πà‡∏≠‡∏ô Bulk Copy
        df_facts_copy['genres_list'] = df_facts_copy['genres_list'].apply(lambda x: '[' + ','.join(map(str, x)) + ']')
        df_facts_copy['production_countries_list'] = df_facts_copy['production_countries_list'].apply(lambda x: '[' + ','.join(map(str, x)) + ']')
        
        create_table_and_bulk_copy(engine, CONN_STRING, df_facts_copy, MOVIE_FACTS_TABLE, FULL_FACTS_TABLE, PRODUCTION_SCHEMA)
        print(f"[SUCCESS] ‡πÇ‡∏´‡∏•‡∏î‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡∏´‡∏•‡∏±‡∏Å‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à! ‡∏ï‡∏≤‡∏£‡∏≤‡∏á: {PRODUCTION_SCHEMA}.{MOVIE_FACTS_TABLE}")

        # --- 5. Aggregation: ‡∏™‡∏£‡∏∏‡∏õ‡∏£‡∏≤‡∏¢‡πÑ‡∏î‡πâ‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢‡∏ï‡∏≤‡∏° Genres (‡πÉ‡∏ä‡πâ df_facts ‡∏ó‡∏µ‡πà‡∏ñ‡∏π‡∏Å‡∏Å‡∏£‡∏≠‡∏á‡πÅ‡∏•‡πâ‡∏ß) ---
        print("‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏™‡∏£‡∏∏‡∏õ‡πÅ‡∏•‡∏∞‡πÇ‡∏´‡∏•‡∏î‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡∏™‡∏£‡∏∏‡∏õ‡∏£‡∏≤‡∏¢‡πÑ‡∏î‡πâ‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢‡∏ï‡∏≤‡∏° Genres...")
        
        # 5.1 Explode Genres
        df_exploded = df_facts.explode('genres_list') # ‡πÉ‡∏ä‡πâ df_facts ‡∏ó‡∏µ‡πà‡∏ñ‡∏π‡∏Å‡∏Å‡∏£‡∏≠‡∏á‡πÅ‡∏•‡πâ‡∏ß
        
        # 5.2 ‡∏Å‡∏£‡∏≠‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Aggregation (‡πÉ‡∏ä‡πâ‡πÄ‡∏á‡∏∑‡πà‡∏≠‡∏ô‡πÑ‡∏Ç Revenue > 0)
        df_filtered = df_exploded[
            (df_exploded['revenue'].notna()) & 
            (df_exploded['revenue'] > 0) & 
            (df_exploded['genres_list'].notna()) &
            (df_exploded['genres_list'] != '') 
        ].copy()
        
        # 5.3 ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì GroupBy
        if len(df_filtered) == 0:
            print("[WARNING] ‡∏´‡∏•‡∏±‡∏á‡∏Å‡∏≤‡∏£‡∏Å‡∏£‡∏≠‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• Genre Summary ‡∏¢‡∏±‡∏á‡∏Ñ‡∏á‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÅ‡∏ñ‡∏ß‡∏ó‡∏µ‡πà‡∏ï‡∏£‡∏á‡∏ï‡∏≤‡∏°‡πÄ‡∏á‡∏∑‡πà‡∏≠‡∏ô‡πÑ‡∏Ç (Revenue > 0).")
            df_genre_summary = pd.DataFrame(columns=['genre_name', 'average_revenue', 'total_movies'])
        else:
            df_genre_summary = df_filtered.groupby('genres_list').agg(
                average_revenue=('revenue', 'mean'),
                total_movies=('movie_fact_id', 'count')
            ).reset_index().rename(columns={'genres_list': 'genre_name'})
            
            df_genre_summary = df_genre_summary.sort_values(by='average_revenue', ascending=False)
        
        # 5.4 ‡πÇ‡∏´‡∏•‡∏î‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡∏™‡∏£‡∏∏‡∏õ
        create_table_and_bulk_copy(engine, CONN_STRING, df_genre_summary, GENRE_SUMMARY_TABLE, FULL_GENRE_TABLE, PRODUCTION_SCHEMA)
        print(f"[SUCCESS] ‡πÇ‡∏´‡∏•‡∏î‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡∏™‡∏£‡∏∏‡∏õ Genres ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à! ‡∏ï‡∏≤‡∏£‡∏≤‡∏á: {PRODUCTION_SCHEMA}.{GENRE_SUMMARY_TABLE}")

    except OperationalError as e:
        print(f"[ERROR] ‡∏Å‡∏≤‡∏£‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠ PostgreSQL ‡∏•‡πâ‡∏°‡πÄ‡∏´‡∏•‡∏ß: ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö Docker ‡πÅ‡∏•‡∏∞ Port")
        print(e)
    except Exception as e:
        print(f"[ERROR] ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏ó‡∏£‡∏≤‡∏ö‡∏™‡∏≤‡πÄ‡∏´‡∏ï‡∏∏‡πÉ‡∏ô‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô Transformation: {e}")

if __name__ == "__main__":
    transform_data()