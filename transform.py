import pandas as pd
from sqlalchemy import create_engine, text
from sqlalchemy.exc import OperationalError
import json
from ast import literal_eval
import numpy as np
# üö® ‡πÉ‡∏ä‡πâ psycopg2 ‡πÅ‡∏•‡∏∞ StringIO ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Bulk Copy
import psycopg2 
from io import StringIO

# --- 1. ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡∏Å‡∏≤‡∏£‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• (‡πÉ‡∏ä‡πâ‡∏Ñ‡πà‡∏≤‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ô) ---
DB_USER = 'DB_AIE321_BIG_DATA'
DB_PASSWORD = '321bigdatawork'
DB_HOST = 'localhost' 
DB_PORT = '6666'      
DB_NAME = 'AIE321' 

# ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ Schema ‡πÅ‡∏•‡∏∞ Table
RAW_SCHEMA = 'raw_data'
RAW_TABLE = 'tmdb_movies_raw'
PRODUCTION_SCHEMA = 'production'
MOVIE_FACTS_TABLE = 'movie_facts'
GENRE_SUMMARY_TABLE = 'genre_average_revenue'

# Connection string ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö psycopg2 ‡πÇ‡∏î‡∏¢‡∏ï‡∏£‡∏á
CONN_STRING = f"dbname={DB_NAME} user={DB_USER} password={DB_PASSWORD} host={DB_HOST} port={DB_PORT}"
FULL_FACTS_TABLE = f'"{PRODUCTION_SCHEMA}"."{MOVIE_FACTS_TABLE}"'
FULL_GENRE_TABLE = f'"{PRODUCTION_SCHEMA}"."{GENRE_SUMMARY_TABLE}"'

# --- 2. ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏ä‡πà‡∏ß‡∏¢‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£ JSON/Array ---
def parse_and_extract_names(json_string):
    """‡πÅ‡∏õ‡∏•‡∏á JSON string ‡πÄ‡∏õ‡πá‡∏ô List ‡∏Ç‡∏≠‡∏á‡∏ä‡∏∑‡πà‡∏≠ (e.g., genre names)"""
    if pd.isna(json_string) or json_string == '[]' or json_string == '':
        return []
    try:
        list_of_dicts = literal_eval(json_string)
        if isinstance(list_of_dicts, list) and all(isinstance(d, dict) for d in list_of_dicts):
            return [d.get('name') or d.get('iso_3166_1', 'Unknown') for d in list_of_dicts]
    except (ValueError, SyntaxError):
        pass
    return []

# --- 3. ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏ä‡πà‡∏ß‡∏¢‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡πÅ‡∏•‡∏∞ Bulk Copy (‡πÉ‡∏ä‡πâ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Å‡∏•‡∏±‡∏ö) ---
def create_table_and_bulk_copy(engine, conn_string, df, table_name_unquoted, table_name_quoted, schema_name):
    """‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡πÄ‡∏õ‡∏•‡πà‡∏≤‡πÅ‡∏•‡∏∞‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏î‡πâ‡∏ß‡∏¢ COPY EXPERT"""
    from pandas.io import sql as pd_sql 
    
    try:
        # A. ‡πÉ‡∏ä‡πâ Pandas ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á CREATE TABLE (DDL)
        table_ddl = pd_sql.get_schema(
            df.head(0),
            name=table_name_unquoted, 
            con=engine, 
            keys=None, 
            schema=schema_name
        )
        
        # B. ‡∏•‡∏ö‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡πÄ‡∏Å‡πà‡∏≤‡πÅ‡∏•‡∏∞‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡πÉ‡∏´‡∏°‡πà
        with engine.begin() as conn:
            conn.execute(text(f"DROP TABLE IF EXISTS {schema_name}.{table_name_unquoted} CASCADE"))
            conn.execute(text(table_ddl))
        
        # C. ‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏î‡πâ‡∏ß‡∏¢ Bulk Copy
        buffer = StringIO()
        # ‡πÉ‡∏ä‡πâ tab (\t) ‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡∏±‡∏ß‡∏Ñ‡∏±‡πà‡∏ô
        df.to_csv(buffer, index=False, header=False, sep='\t', encoding='utf-8') 
        buffer.seek(0)
        
        copy_command = f"""COPY {table_name_quoted} FROM STDIN WITH (FORMAT CSV, DELIMITER E'\\t')"""
        
        with psycopg2.connect(conn_string) as conn:
            with conn.cursor() as cursor:
                cursor.copy_expert(copy_command, buffer) 
            conn.commit() 
        
        return True

    except Exception as e:
        print(f"[ERROR] Bulk Copy to {schema_name}.{table_name_unquoted} Failed: {e}")
        raise


# --- 4. ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏´‡∏•‡∏±‡∏Å‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÅ‡∏õ‡∏•‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• (The Refinery) ---
def transform_data():
    try:
        # 1. ‡∏™‡∏£‡πâ‡∏≤‡∏á Engine ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£ DDL (Create Table, Drop Table)
        engine = create_engine(f'postgresql://{DB_USER}:{DB_PASSWORD}@{DB_HOST}:{DB_PORT}/{DB_NAME}')
        
        # 2. ‡∏™‡∏£‡πâ‡∏≤‡∏á Schema Production (‡∏ñ‡πâ‡∏≤‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏°‡∏µ)
        with engine.begin() as conn:
            conn.execute(text(f"CREATE SCHEMA IF NOT EXISTS {PRODUCTION_SCHEMA}"))
            print(f"[SUCCESS] Schema '{PRODUCTION_SCHEMA}' ‡∏ñ‡∏π‡∏Å‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏£‡πâ‡∏≠‡∏¢‡πÅ‡∏•‡πâ‡∏ß")
        
        # 3. ‡∏≠‡πà‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏î‡∏¥‡∏ö (‡πÉ‡∏ä‡πâ psycopg2 ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏≠‡πà‡∏≤‡∏ô)
        print(f"‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏≠‡πà‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏î‡∏¥‡∏ö‡∏à‡∏≤‡∏Å {RAW_SCHEMA}.{RAW_TABLE} ‡πÇ‡∏î‡∏¢‡πÉ‡∏ä‡πâ psycopg2...")
        
        with psycopg2.connect(CONN_STRING) as conn:
            query = f"SELECT * FROM {RAW_SCHEMA}.{RAW_TABLE}"
            df = pd.read_sql_query(query, con=conn) 
        
        print(f"[SUCCESS] ‡∏≠‡πà‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏¥‡πâ‡∏ô ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡πÅ‡∏ñ‡∏ß: {len(df):,}")
        
        # --- 4. Data Cleaning ‡πÅ‡∏•‡∏∞ Feature Engineering ---
        print("‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÅ‡∏õ‡∏•‡∏á‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå Genres, Production Countries, Cast, Director ‡πÅ‡∏•‡∏∞ Writers...")
        
        # ... (‡∏™‡πà‡∏ß‡∏ô‡∏Å‡∏≤‡∏£‡∏ó‡∏≥ Data Cleaning ‡∏¢‡∏±‡∏á‡∏Ñ‡∏á‡πÄ‡∏î‡∏¥‡∏°) ...
        json_cols = ['genres', 'production_countries', 'production_companies', 'spoken_languages', 'cast', 'writers', 'producers']
        for col in json_cols:
            df[f'{col}_list'] = df[col].astype(str).apply(parse_and_extract_names)
            
        numeric_cols = ['revenue', 'budget', 'runtime', 'vote_count', 'imdb_votes', 'imdb_rating', 'popularity']
        for col in numeric_cols:
            df[col] = pd.to_numeric(df[col], errors='coerce')

        df['release_year'] = pd.to_datetime(df['release_date'], errors='coerce').dt.year
        df['movie_fact_id'] = df['id'].astype('Int64') 

        movie_facts_cols = [
            'movie_fact_id', 'title', 'original_title', 'release_year', 'release_date',
            'status', 'runtime', 'budget', 'revenue', 'vote_average', 'vote_count',
            'imdb_rating', 'imdb_votes', 'popularity', 'original_language',
            'genres_list', 'production_countries_list'
        ]
        df_facts = df[movie_facts_cols].copy()
        
        # --- 5. ‡πÇ‡∏´‡∏•‡∏î‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡∏´‡∏•‡∏±‡∏Å: production.movie_facts (‡πÉ‡∏ä‡πâ Bulk Copy) ---
        print(f"‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÇ‡∏´‡∏•‡∏î‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡∏´‡∏•‡∏±‡∏Å {PRODUCTION_SCHEMA}.{MOVIE_FACTS_TABLE} ‡∏î‡πâ‡∏ß‡∏¢ Bulk Copy...")
        
        # ‡∏ï‡πâ‡∏≠‡∏á‡πÅ‡∏õ‡∏•‡∏á‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå List ‡πÉ‡∏´‡πâ‡πÄ‡∏õ‡πá‡∏ô String ‡∏Å‡πà‡∏≠‡∏ô‡∏ó‡∏≥ Bulk Copy
        df_facts_copy = df_facts.copy()
        df_facts_copy['genres_list'] = df_facts_copy['genres_list'].apply(lambda x: '[' + ','.join(map(str, x)) + ']')
        df_facts_copy['production_countries_list'] = df_facts_copy['production_countries_list'].apply(lambda x: '[' + ','.join(map(str, x)) + ']')
        
        create_table_and_bulk_copy(engine, CONN_STRING, df_facts_copy, MOVIE_FACTS_TABLE, FULL_FACTS_TABLE, PRODUCTION_SCHEMA)
        print(f"[SUCCESS] ‡πÇ‡∏´‡∏•‡∏î‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡∏´‡∏•‡∏±‡∏Å‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à! ‡∏ï‡∏≤‡∏£‡∏≤‡∏á: {PRODUCTION_SCHEMA}.{MOVIE_FACTS_TABLE}")

        # --- 6. Aggregation: ‡∏™‡∏£‡∏∏‡∏õ‡∏£‡∏≤‡∏¢‡πÑ‡∏î‡πâ‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢‡∏ï‡∏≤‡∏° Genres (‡∏ï‡∏≠‡∏ö‡πÇ‡∏à‡∏ó‡∏¢‡πå Q1) ---
        print("‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏™‡∏£‡∏∏‡∏õ‡πÅ‡∏•‡∏∞‡πÇ‡∏´‡∏•‡∏î‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡∏™‡∏£‡∏∏‡∏õ‡∏£‡∏≤‡∏¢‡πÑ‡∏î‡πâ‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢‡∏ï‡∏≤‡∏° Genres...")
        
        df_exploded = df_facts.explode('genres_list')
        df_filtered = df_exploded[(df_exploded['revenue'] > 0) & (df_exploded['budget'] > 0) & (df_exploded['genres_list'].notna())].copy()
        
        df_genre_summary = df_filtered.groupby('genres_list').agg(
            average_revenue=('revenue', 'mean'),
            total_movies=('movie_fact_id', 'count')
        ).reset_index().rename(columns={'genres_list': 'genre_name'})
        
        df_genre_summary = df_genre_summary.sort_values(by='average_revenue', ascending=False)
        
        # 7. ‡πÇ‡∏´‡∏•‡∏î‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡∏™‡∏£‡∏∏‡∏õ (‡πÉ‡∏ä‡πâ Bulk Copy)
        create_table_and_bulk_copy(engine, CONN_STRING, df_genre_summary, GENRE_SUMMARY_TABLE, FULL_GENRE_TABLE, PRODUCTION_SCHEMA)
        print(f"[SUCCESS] ‡πÇ‡∏´‡∏•‡∏î‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡∏™‡∏£‡∏∏‡∏õ Genres ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à! ‡∏ï‡∏≤‡∏£‡∏≤‡∏á: {PRODUCTION_SCHEMA}.{GENRE_SUMMARY_TABLE}")

    except OperationalError as e:
        print(f"[ERROR] ‡∏Å‡∏≤‡∏£‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠ PostgreSQL ‡∏•‡πâ‡∏°‡πÄ‡∏´‡∏•‡∏ß: ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö Docker ‡πÅ‡∏•‡∏∞ Port")
        print(e)
    except Exception as e:
        print(f"[ERROR] ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏ó‡∏£‡∏≤‡∏ö‡∏™‡∏≤‡πÄ‡∏´‡∏ï‡∏∏‡πÉ‡∏ô‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô Transformation: {e}")

if __name__ == "__main__":
    transform_data()